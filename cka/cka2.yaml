# CKA Mock Exam â€“ Rapid Memorization Cheat Sheet (Mock 2)

---

## Q1 â€“ StorageClass + Static PV + PVC
**Context:** Create local static storage (SC â†’ PV â†’ PVC).

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: orange-stc-cka07-str
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
```

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: orange-pv-cka07-str
spec:
  capacity:
    storage: 150Mi
  accessModes: [ReadWriteOnce]
  persistentVolumeReclaimPolicy: Retain
  storageClassName: orange-stc-cka07-str
  local:
    path: /opt/orange-data-cka07-str
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values: [cluster1-controlplane]
```

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: orange-pvc-cka07-str
spec:
  accessModes: [ReadWriteOnce]
  storageClassName: orange-stc-cka07-str
  volumeName: orange-pv-cka07-str
  resources:
    requests:
      storage: 128Mi
```

```bash
kubectl apply -f storage.yaml
```

---

## Q2 â€“ Find highest CPU node across clusters
**Context:** Compare node CPU usage across multiple clusters.

```bash
ssh cluster1-controlplane "kubectl top node --no-headers | sort -nr -k2 | head -1"
ssh cluster3-controlplane "kubectl top node --no-headers | sort -nr -k2 | head -1"
ssh cluster4-controlplane "kubectl top node --no-headers | sort -nr -k2 | head -1"
```

```bash
echo cluster3,cluster3-controlplane > /opt/high_cpu_node
```

---

## Q3 â€“ PriorityClass
**Context:** Assign high scheduling priority to a deployment.

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000
globalDefault: false
```

```bash
kubectl edit deploy hp-webapp -n high-priority
```

```text
priorityClassName: high-priority
```

---

## Q4 â€“ Helm upgrade (validate â†’ install â†’ uninstall)
**Context:** Replace old Helm release with new version.

```bash
helm ls -n default
helm lint ./new-version
helm install --generate-name ./new-version -n default
helm uninstall webpage-server-01 -n default
```

---

## Q5 â€“ Deployment blocked by ResourceQuota
**Context:** Pods fail due to memory quota.

```bash
kubectl describe rs backend-api-<hash>
```

```bash
kubectl edit deploy backend-api
```

```text
Reduce requests.memory to fit quota
Do NOT edit ResourceQuota
```

```bash
kubectl delete rs backend-api-<old-hash>
```

---

## Q6 â€“ Vertical Pod Autoscaler
**Context:** Auto-adjust CPU/memory requests.

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: analytics-vpa
  namespace: cka24456
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: analytics-deployment
  updatePolicy:
    updateMode: Auto
```

---

## Q7 â€“ Ingress 503 due to wrong protocol
**Context:** Ingress exists but service protocol is wrong.

```bash
kubectl edit svc pink-svc-cka16-trb
```

```text
protocol: UDP âŒ
protocol: TCP âœ…
```

---

## Q8 â€“ Extract ERROR logs
**Context:** Save only ERROR logs to file.

```bash
kubectl logs -n beta-cka01-arch beta-pod-cka01-arch | grep ERROR \
> /root/beta-pod-cka01-arch_errors
```

---

## Q9 â€“ Service has no endpoints
**Context:** Service selector mismatch.

```bash
kubectl describe svc curlme-cka01-svcn
kubectl delete svc curlme-cka01-svcn
kubectl expose pod curlme-cka01-svcn --port=80
```

---

## Q10 â€“ App fails due to missing Secret
**Context:** Web app cannot connect to MySQL.

```bash
kubectl create secret generic db-secret-wl05 -n canara-wl05 \
--from-literal=DB_Host=mysql-svc-wl05 \
--from-literal=DB_User=root \
--from-literal=DB_Password=password123
```

```yaml
envFrom:
- secretRef:
    name: db-secret-wl05
```

```bash
kubectl replace -f webapp.yaml --force
```

---

## Q11 â€“ CrashLoop due to ConfigMap mount
**Context:** ConfigMap mounted on file without subPath.

```bash
kubectl edit deploy nginx-frontend -n cka4974
```

```yaml
volumeMounts:
- mountPath: /etc/nginx/conf.d/default.conf
  name: nginx-conf-vol
  subPath: default.conf
```

---

## Q12 â€“ Ingress 404 (wrong host/service/port)
**Context:** Ingress routes to wrong backend.

```bash
kubectl edit ingress nodeapp-ing-cka08-trb
```

```text
host: kodekloud-ingress.app
service: nodeapp-svc-cka08-trb
port: 3000
```

---

## Q13 â€“ Gateway HTTPS with TLS
**Context:** Enable HTTPS on port 443.

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: web-gateway
  namespace: cka5673
spec:
  gatewayClassName: kodekloud
  listeners:
  - name: https
    protocol: HTTPS
    port: 443
    hostname: kodekloud.com
    tls:
      certificateRefs:
      - name: kodekloud-tls
```

---

## Q14 â€“ HTTPRoute path-based routing
**Context:** /api â†’ api-service, / â†’ web-service.

```yaml
rules:
- matches:
  - path:
      type: PathPrefix
      value: /api
  backendRefs:
  - name: api-service
    port: 8080
- matches:
  - path:
      type: PathPrefix
      value: /
  backendRefs:
  - name: web-service
    port: 80
```

---

## Q15 â€“ PVC bound to specific PV
**Context:** Claim exact PV by name.

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: apple-pvc-cka04-str
spec:
  volumeName: apple-pv-cka04-str
  storageClassName: manual
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 40Mi
```

---

## Q16 â€“ kubectl broken (API server down)
**Context:** kubelet missing â†’ API server not running.

```bash
crictl ps -a
systemctl status kubelet
kubeadm version
```

```bash
sudo apt install -y kubelet=1.32.0-1.1
sudo systemctl start kubelet
```

```bash
kubectl get nodes
```

---

## ðŸ”‘ Exam Pattern Hooks
- PVC not binding â†’ **nodeAffinity / SC mismatch**
- Pod Pending â†’ **Quota / Scheduler**
- 503 ingress â†’ **Service protocol**
- No endpoints â†’ **Selector mismatch**
- CrashLoop + ConfigMap â†’ **subPath**
- kubectl broken â†’ **kubelet / apiserver**

